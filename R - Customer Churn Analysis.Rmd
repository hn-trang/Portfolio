---
title: "MDA611 Assignment 2"
output: pdf_document
date: "2023-05-14"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#Data Cleaning
#from the given A2customer csv file, CustID column was removed before importing as it can cause redundancy in data. 
```

```{r}
#imported data turned out to be as follows
df <- read.csv('A2Customer.csv') 
head(df)
```
```{r}
#installing necessary packages

install.packages("caret") 
install.packages("ggthemes")
install.packages("party")
install.packages('tidyverse')
install.packages("randomForest")
```


```{r}
#importing libraries
library(plyr)
library(corrplot)
library(ggplot2)
library(gridExtra)
library(ggthemes)
library(caret)
library(MASS)
library(randomForest)
library(party)
```

```{r}
str(df)
```

```{r}
is.na(df)
sum(is.na(df))
```
```{r}
# Create a boxplot to check whether their exists any outliers in the dataset
boxplot(df$LengthOfPlan)
boxplot(df$MonthlyFees)
boxplot(df$TotalFees)
```

```{r}
# Visualize the distribution of numerical variables using histograms
hist(df$LengthOfPlan, breaks = 10, main = "LengthOfPlan", xlab = "LengthOfPlan")
hist(df$MonthlyFees, breaks = 10, main = "MonthlyFees", xlab = "MonthlyFees")
hist(df$TotalFees, breaks = 10, main = "TotalFees", xlab = "TotalFees")
```
```{r}
#Following the Central Limit Theoreom, it can be assumed that numerical variables are normally distributed as we have
#more than 7000 values

#no outliers detected from the boxplots
```


```{r}
#after examining the dataset, we do chi-square test on 4 categorial variables to check if there is significant association between them. 
#If their association is proved then we do cramerV test to check their correlation and decide on which ones to keep

cont_table <- table(df$OnlineSecurityEnabled, df$OnlineBackupEnabled)
chi_square_result <- chisq.test(cont_table)
chi_square_value <- chi_square_result$statistic  
p_value <- chi_square_result$p.value
n <- sum(chi_square_result$observed)  
k <- min(dim(chi_square_result$observed))


cramers_v <- sqrt(chi_square_value/ (n * (k - 1)))


print(chi_square_result)
print(p_value)
print(cramers_v)
#Value of CramerV coefficent close to one suggests that the two variables are highly correlated. 
#Thus keeping one of them is the best choice
```

```{r}
cont_table1 <- table(df$OnlineSecurityEnabled, df$TechSupportEnabled)
chi_square_result1 <- chisq.test(cont_table1)
chi_square_value1 <- chi_square_result1$statistic  
p_value1 <- chi_square_result1$p.value
n <- sum(chi_square_result1$observed)  
k <- min(dim(chi_square_result1$observed))
cramers_v1 <- sqrt(chi_square_value1 / (n * (k - 1)))


print(chi_square_result1)
print(p_value1)
print(cramers_v1)

#Value of CramerV coefficent close to one suggests that the two variables are highly correlated. Thus keeping one of them is the best choicets
```
```{r}
cont_table2 <- table(df$OnlineSecurityEnabled, df$DeviceProtectionEnabled)
chi_square_result2 <- chisq.test(cont_table2)
chi_square_value2 <- chi_square_result2$statistic  
p_value2 <- chi_square_result2$p.value
n <- sum(chi_square_result2$observed)  
k <- min(dim(chi_square_result2$observed))
cramers_v2 <- sqrt(chi_square_value2 / (n * (k - 1)))


print(chi_square_result2)
print(p_value2)
print(cramers_v2)

#Value of CramerV coefficent close to one suggests that the two variables are highly correlated. Thus keeping one of them is the best choice
```

```{r}
#columns OnlineSecurityEnabled, OnlineBackupEnabled, DeviceProtectionEnabled, TechSupportEnabled, StreamingTvPlan and StreamingMoviePlan have No internet service option other than "yes" and "no". That option is also converted to "no" to make them binary columns as it means the same.  
cols_recode1 <- c(9:14)
for(i in 1:ncol(df[,cols_recode1])) {
        df[,cols_recode1][,i] <- as.factor(mapvalues
                                              (df[,cols_recode1][,i], from =c("No internet service"),to=c("No")))
}
```
```{r}
print(df[,11])
```
```{r}
#column MulitpleLines has No internet service option other than "yes" and "no". That option is also converted to "no" to make them binary columns as it means the same
df$MultipleLinesPlan <- as.factor(mapvalues(df$MultipleLinesPlan, 
                                           from=c("No phone service"),
                                           to=c("No")))
```


```{r}
#SeniorCard column has 1 and 0  which are changed to yes and no and then factored for model
df$SeniorCard <- as.factor(mapvalues(df$SeniorCard,
                                      from=c("0","1"),
                                      to=c("No", "Yes")))
```

```{r}
#factorizing the remaining categorical variables so that they can be fed onto the main model

remaining_cat <- c('Sex','Married', 'HasChildren','BundledPlan', 'InternetServicePlan', 'ContractType','ElectronicBilling', 'PaymentType','Switched')
for (var in remaining_cat) {
  df[[var]] <- factor(df[[var]])
}
```







```{r}
#correlation of numeric variables

numeric_var <- sapply(df, is.numeric)
corr.matrix <- cor(df[,numeric_var])
corrplot(corr.matrix,
         main = "\n\nCorrelation Plot for Numerical Variables", method ='number')
```
```{r}
group_lop <- function(LengthOfPlan){
    if (LengthOfPlan >= 0 & LengthOfPlan <= 12){
        return('0-12 Month')
    }else if(LengthOfPlan > 12 & LengthOfPlan <= 24){
        return('12-24 Month')
    }else if (LengthOfPlan > 24 & LengthOfPlan <= 48){
        return('24-48 Month')
    }else if (LengthOfPlan > 48 & LengthOfPlan <=60){
        return('48-60 Month')
    }else if (LengthOfPlan > 60){
        return('> 60 Month')
    }
}
df$lop_group <- sapply(df$LengthOfPlan,group_lop)
df$lop_group <- as.factor(df$lop_group)
```

```{r}
str(df)
```
```{r}
#Plotting distributions to check each column


p1 <- ggplot(df, aes(x=Sex)) + ggtitle("Sex") + xlab("Sex") +
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 0.5) + ylab("Percentage") + coord_flip() + theme_minimal()
p2 <- ggplot(df, aes(x=SeniorCard)) + ggtitle("Senior Card") + xlab("Senior Card") + 
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 0.5) + ylab("Percentage") + coord_flip() + theme_minimal()
p3 <- ggplot(df, aes(x=Married)) + ggtitle("Married") + xlab("Married") + 
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 0.5) + ylab("Percentage") + coord_flip() + theme_minimal()
p4 <- ggplot(df, aes(x=HasChildren)) + ggtitle("Has Children") + xlab("Has Children") +
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 0.5) + ylab("Percentage") + coord_flip() + theme_minimal()
grid.arrange(p1, p2, p3, p4, ncol=2)
```
```{r}
p5 <- ggplot(df, aes(x=BundledPlan)) + ggtitle("Bundle Plan") + xlab("Bundle Plan") +
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 0.5) + ylab("Percentage") + coord_flip() + theme_minimal()
p6 <- ggplot(df, aes(x=MultipleLinesPlan)) + ggtitle("Multiple Lines") + xlab("Multiple Lines") + 
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 0.5) + ylab("Percentage") + coord_flip() + theme_minimal()
p7 <- ggplot(df, aes(x=InternetServicePlan)) + ggtitle("Internet Service") + xlab("Internet Service") + 
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 0.5) + ylab("Percentage") + coord_flip() + theme_minimal()
p8 <- ggplot(df, aes(x=OnlineSecurityEnabled)) + ggtitle("Online Security") + xlab("Online Security") +
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 0.5) + ylab("Percentage") + coord_flip() + theme_minimal()
grid.arrange(p5, p6, p7, p8, ncol=2)
```
```{r}
p12 <- ggplot(df, aes(x=StreamingTVPlan)) + ggtitle("Streaming TV") + xlab("Streaming TV") +
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 0.5) + ylab("Percentage") + coord_flip() + theme_minimal()
grid.arrange(p12, ncol=2)
p13 <- ggplot(df, aes(x=StreamingMoviesPlan)) + ggtitle("Streaming Movies") + xlab("Streaming Movies") +
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 0.5) + ylab("Percentage") + coord_flip() + theme_minimal()
p14 <- ggplot(df, aes(x=ContractType)) + ggtitle("Contract") + xlab("Contract") + 
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 0.5) + ylab("Percentage") + coord_flip() + theme_minimal()
p15 <- ggplot(df, aes(x=ElectronicBilling)) + ggtitle("Electronic Billing") + xlab("Electronic Billing") + 
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 0.5) + ylab("Percentage") + coord_flip() + theme_minimal()
p16 <- ggplot(df, aes(x=PaymentType)) + ggtitle("Payment Type") + xlab("Payment Type") +
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 0.5) + ylab("Percentage") + coord_flip() + theme_minimal()
p17 <- ggplot(df, aes(x=lop_group)) + ggtitle("Length of Plan Group") + xlab("Length of Plan Group") +
  geom_bar(aes(y = 100*(..count..)/sum(..count..)), width = 0.5) + ylab("Percentage") + coord_flip() + theme_minimal()
grid.arrange(p12, p13, p14, p15, p16, p17, ncol=2)

#all columns are significant values of each option so keeping them all in the main analysis
```
```{r}
#lengthofPlan and TotalFees are highly correlated to MonthlyFees so keeping only that in the analysis and removing the other two. 
#OnlineBackupEnabled , DeviceProtectionEnabled and TechSupportEnabled were found to be highly correalted with OnlineSupportEnabled with a cramerV coefficent of over 0.7 hence they were also removed. 

df$LengthOfPlan <- NULL
df$TotalFees <- NULL
df$OnlineBackupEnabled <- NULL
df$DeviceProtectionEnabled <- NULL
df$TechSupportEnabled <- NULL
```



```{r}
#dividing the data into train and test sets
intrain<- createDataPartition(df$Switched,p=0.7,list=FALSE)
set.seed(2017)
training<- df[intrain,]
testing<- df[-intrain,]
```

```{r}
#70/30 ratio ensured
dim(training); dim(testing)
```
```{r}
#activating Logistic regression model
LogModel <- glm(Switched ~ .,family=binomial(link="logit"),data=training)
print(summary(LogModel))
```
```{r}
anova(LogModel, test="Chisq")
```
```{r}
#printing testing results and accuracy
testing$Switched <- as.character(testing$Switched)
testing$Switched[testing$Switched=="No"] <- "0"
testing$Switched[testing$Switched=="Yes"] <- "1"
fitted.results <- predict(LogModel,newdata=testing,type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)
misClasificError <- mean(fitted.results != testing$Switched)
print(paste('Logistic Regression Accuracy',1-misClasificError))
```

```{r}
print("Confusion Matrix for Logistic Regression"); table(testing$Switched, fitted.results > 0.5)
```
```{r}
library(MASS)
exp(cbind(OR=coef(LogModel), confint(LogModel)))
```
```{r}
#installing packages for decision trees model
install.packages("survival")
```
```{r}
install.packages("rpart")
```


```{r}
install.packages("rpart.plot")
```


```{r}
library(rpart)  # For building decision trees
library(rpart.plot)  # For visualizing decision trees

```


```{r}
#running decision trees model
modeldt <- rpart(Switched ~ ., data = training, method = "class")
```


```{r}
rpart.plot(modeldt)
```
```{r}
predictions <- predict(modeldt, newdata = testing, type = "class")

```


```{r}
#pritnting test results
confusion_matrix <- table(actual = testing$Switched, predicted = predictions)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(confusion_matrix)
print(accuracy)

```


```{r}
#running random forest model for list of important features
modelrf <- randomForest(Switched ~ ., data = training, ntree = 100)

```


```{r}
#printing important features in accordance with their Decrease in Gini Value
importance <- importance(modelrf)
print(importance)
```
```{r}
#10 of the most important features are as follows
sorted_importance <- importance[order(importance[, 1], decreasing = TRUE), ]
print(sorted_importance[1:10])

```


```{r}
predictions1 <- predict(modelrf, newdata = testing)

```


```{r}

confusion_matrix1 <- table(actual = testing$Switched, predicted = predictions1)
accuracy1 <- sum(diag(confusion_matrix1)) / sum(confusion_matrix1)
print(confusion_matrix1)
print(accuracy1)

```
